from pyspark.sql.functions import col,year,month,sum

df = orders.filter((year(col('order_date')) == 2019) & (month(col('order_date')) == 3))

df_revenue = df.groupBy(col('cust_id')).agg(sum(col('total_order_cost')).alias('revenue')).orderBy(col('revenue').desc())

df_revenue.toPandas()
